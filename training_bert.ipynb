{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T04:34:44.555485344Z",
     "start_time": "2023-12-03T04:34:44.513906311Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AdamW\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "336e3f59095cf075",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T04:32:45.651388083Z",
     "start_time": "2023-12-03T04:32:45.605108929Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_path = 'qa_dataset.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29c40423370cfb0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T04:32:56.932934713Z",
     "start_time": "2023-12-03T04:32:56.153247862Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original \n",
    "# Prepare data \n",
    "\n",
    "# Tokenizing the data\n",
    "# inputs = tokenizer([x['question'] + \" [SEP] \" + x['answer'] for x in data], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Assuming binary classification (change as needed)\n",
    "# labels = torch.tensor([1 if x['answer_length'] > 100 else 0 for x in data])\n",
    "\n",
    "# Create a dataset\n",
    "# dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "\n",
    "# Tokenizing the data\n",
    "max_length = max(len(tokenizer.encode(x['question'] + \" [SEP] \" + x['answer'])) for x in data)\n",
    "tokenized_data = [tokenizer(x['question'] + \" [SEP] \" + x['answer'], \n",
    "                            padding='max_length',  \n",
    "                            max_length=max_length,  \n",
    "                            truncation=True, \n",
    "                            return_tensors=\"pt\") for x in data]\n",
    "\n",
    "# input\n",
    "input_ids = torch.cat([item['input_ids'] for item in tokenized_data], dim=0)\n",
    "attention_masks = torch.cat([item['attention_mask'] for item in tokenized_data], dim=0)\n",
    "labels = torch.tensor([1 if x['answer_length'] > 100 else 0 for x in data])\n",
    "\n",
    "# dataset seprate\n",
    "input_ids_train, input_ids_test, attention_masks_train, attention_masks_test, labels_train, labels_test = train_test_split(\n",
    "    input_ids, attention_masks, labels, train_size=0.7, random_state=42)\n",
    "\n",
    "# create dataset\n",
    "train_dataset = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "test_dataset = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b2a94ce5138fac5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T04:33:45.490716461Z",
     "start_time": "2023-12-03T04:33:15.276570494Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    }
   ],
   "source": [
    "# check GPU is work\n",
    "# Train the model using a suitable optimizer and loss function.\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 101, 2515, 2023,  ...,    0,    0,    0],\n",
       "         [ 101, 2064, 2017,  ...,    0,    0,    0],\n",
       "         [ 101, 2054, 2003,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101, 2064, 2009,  ...,    0,    0,    0],\n",
       "         [ 101, 7632, 2515,  ...,    0,    0,    0],\n",
       "         [ 101, 2003, 1996,  ...,    0,    0,    0]]),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " tensor([1, 0, 1, 0, 1, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a16023ef51bad72",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andy Cui\\.conda\\envs\\nlp\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1: 100%|██████████| 143/143 [00:36<00:00,  3.89it/s, loss=0.404]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 finished. Loss: 0.4036314932408033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 143/143 [00:36<00:00,  3.94it/s, loss=0.213] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 finished. Loss: 0.21305178865217245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 143/143 [00:36<00:00,  3.93it/s, loss=0.0929]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 finished. Loss: 0.092923402796024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 143/143 [00:36<00:00,  3.92it/s, loss=0.0364]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 finished. Loss: 0.03640105896889903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 143/143 [00:36<00:00,  3.93it/s, loss=0.0228]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 finished. Loss: 0.022826942024179377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 143/143 [00:36<00:00,  3.88it/s, loss=0.021]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 finished. Loss: 0.02102877881208604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 143/143 [00:36<00:00,  3.91it/s, loss=0.02]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 finished. Loss: 0.020017903966917102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 143/143 [00:36<00:00,  3.92it/s, loss=0.0171] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 finished. Loss: 0.01708418216802167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 143/143 [00:36<00:00,  3.89it/s, loss=0.018]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 finished. Loss: 0.018044854329501675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 143/143 [00:36<00:00,  3.92it/s, loss=0.00423] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 finished. Loss: 0.004225602669810707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 143/143 [00:37<00:00,  3.86it/s, loss=0.0249]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 finished. Loss: 0.02488790063180967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 143/143 [00:37<00:00,  3.85it/s, loss=0.0107] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 finished. Loss: 0.010675052028650848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 143/143 [00:36<00:00,  3.89it/s, loss=0.00065] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 finished. Loss: 0.0006500836421077798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 143/143 [00:36<00:00,  3.88it/s, loss=0.000461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 finished. Loss: 0.0004606472091811182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 143/143 [00:36<00:00,  3.87it/s, loss=0.000496]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 finished. Loss: 0.000496425261615997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 143/143 [00:36<00:00,  3.88it/s, loss=0.0161] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 finished. Loss: 0.016068160734884276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 143/143 [00:36<00:00,  3.87it/s, loss=0.000846]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 finished. Loss: 0.0008460047885399455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 143/143 [00:36<00:00,  3.91it/s, loss=0.000452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 finished. Loss: 0.0004516881196580541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 143/143 [00:36<00:00,  3.88it/s, loss=0.000235]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 finished. Loss: 0.00023507781013751964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 143/143 [00:36<00:00,  3.90it/s, loss=0.000193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 finished. Loss: 0.0001931712203850429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 143/143 [00:36<00:00,  3.90it/s, loss=0.00016] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 finished. Loss: 0.0001600782702012652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 143/143 [00:36<00:00,  3.90it/s, loss=0.000148]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 finished. Loss: 0.00014799436498547325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 143/143 [00:36<00:00,  3.93it/s, loss=0.000122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 finished. Loss: 0.00012165511135252883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 143/143 [00:36<00:00,  3.91it/s, loss=0.000123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 finished. Loss: 0.00012251696547524275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 143/143 [00:36<00:00,  3.90it/s, loss=9.82e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 finished. Loss: 9.820316341205767e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "batch_size = 8\n",
    "epochs = 25\n",
    "\n",
    "# Prepare for epoch_losses\n",
    "epoch_losses = []\n",
    "\n",
    "# Create dataloader\n",
    "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\")\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        # b_input_ids, b_input_mask, b_labels = batch\n",
    "        b_input_ids, b_input_mask, b_labels = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
    "        model.zero_grad()\n",
    "\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the progress bar\n",
    "        progress_bar.set_postfix({'loss': total_loss/len(train_dataloader)})\n",
    "        \n",
    "    # Calculate and store the average loss for this epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    epoch_losses.append(avg_loss)\n",
    "    \n",
    "    # Save the model after each epoch\n",
    "    # model_save_file = os.path.join(model_save_path, f'bert_model_epoch_{epoch+1}.pt')\n",
    "    # torch.save(model.state_dict(), model_save_file)\n",
    "\n",
    "    # Closing the progress bar and printing the epoch loss\n",
    "    progress_bar.close()\n",
    "    print(f\"Epoch {epoch+1} finished. Loss: {total_loss/len(train_dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Parameters:\n",
      "Batch Size: 8\n",
      "Epochs: 25\n",
      "Learning Rate: 2e-05\n",
      "Beta1: 0.9\n",
      "Beta2: 0.999\n",
      "Training completed. Final model saved to models\\bert_final_model_1.pt\n"
     ]
    }
   ],
   "source": [
    "model_save_path = 'models'  \n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "final_model_save_file = os.path.join(model_save_path, 'bert_final_model_1.pt')\n",
    "torch.save(model.state_dict(), final_model_save_file)\n",
    "\n",
    "# print paramter\n",
    "print(\"Training Parameters:\")\n",
    "print(f\"Batch Size: {batch_size}\")\n",
    "print(f\"Epochs: {epochs}\")\n",
    "print(f\"Learning Rate: {optimizer.defaults['lr']}\")\n",
    "print(f\"Beta1: {optimizer.defaults['betas'][0]}\")\n",
    "print(f\"Beta2: {optimizer.defaults['betas'][1]}\")\n",
    "\n",
    "print(f\"Training completed. Final model saved to {final_model_save_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkUAAAHFCAYAAAD8Jo2EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABcF0lEQVR4nO3deVhUZf8/8PfMwMwAwgiCLAqIKyKuoAiGSyaKaW49UiZqaWYuRTw+JY+7WWi/UtIU86kkKxFNLb+lKWYqpuYGZrlkuUAKIqgM+zJzfn8gY+MAsgycAd6v6zqXzJn7nPmc8STv7nOf+0gEQRBARERE1MRJxS6AiIiIyBQwFBERERGBoYiIiIgIAEMREREREQCGIiIiIiIADEVEREREABiKiIiIiAAwFBEREREBYCgiIiIiAsBQRFRrEomkSsuhQ4dq9TlLliyBRCKp0baHDh0ySg21+eyvv/663j+7Jk6cOIF//etfcHZ2hlwuh5OTE5599lkcP35c7NIMXL9+vdJzbsmSJWKXiDZt2mDEiBFil0FUJWZiF0DU0D36y/Ltt9/GTz/9hIMHD+qt9/LyqtXnTJs2DcOGDavRtr169cLx48drXUNjt3btWoSFhaFPnz5477334O7ujuTkZKxbtw5PPPEEPvzwQ8yePVvsMg3MmTMHEyZMMFjfunVrEaohargYiohqqW/fvnqvHRwcIJVKDdY/Ki8vD5aWllX+nNatW9f4l5yNjc1j62nqfv75Z4SFhWH48OHYtWsXzMwe/vP43HPPYcyYMXj99dfRs2dP9OvXr97qys/Ph1KprLSX0M3NjX+/REbAy2dE9WDgwIHw9vbGkSNHEBAQAEtLS7z00ksAgLi4OAQFBcHZ2RkWFhbo3Lkz5s2bh9zcXL19lHf5rOzSxA8//IBevXrBwsICnp6e+Oyzz/TalXf5bMqUKWjWrBn+/PNPDB8+HM2aNYOrqyv+/e9/o7CwUG/7v//+G88++yysra3RvHlzvPDCCzh16hQkEgliYmKM8h399ttvGDVqFGxtbaFUKtGjRw98/vnnem20Wi2WL1+OTp06wcLCAs2bN0e3bt3w4Ycf6trcuXMH06dPh6urKxQKBRwcHNCvXz8cOHCg0s+PjIyERCJBdHS0XiACADMzM6xfvx4SiQQrVqwAAHzzzTeQSCT48ccfDfYVHR0NiUSCX3/9Vbfu9OnTeOaZZ2BnZwelUomePXti27ZtetvFxMRAIpFg//79eOmll+Dg4ABLS0uDv4+aKDsHExIS0LdvX1hYWKBVq1ZYuHAhNBqNXtu7d+9i5syZaNWqFeRyOdq2bYv58+cb1KHVarF27Vr06NFD9/fRt29f7N692+DzH3eO5uXlYe7cufDw8IBSqYSdnR18fX0RGxtb62Mnqir2FBHVk9TUVEycOBFvvvkm3n33XUilpf9PcuXKFQwfPhxhYWGwsrLCpUuXsHLlSpw8edLgElx5zp07h3//+9+YN28eHB0d8cknn2Dq1Klo3749+vfvX+m2xcXFeOaZZzB16lT8+9//xpEjR/D2229DpVJh0aJFAIDc3FwMGjQId+/excqVK9G+fXv88MMPCAkJqf2X8sDly5cREBCAli1bYs2aNWjRogW+/PJLTJkyBbdv38abb74JAHjvvfewZMkSLFiwAP3790dxcTEuXbqE+/fv6/YVGhqKs2fP4p133kHHjh1x//59nD17FpmZmRV+vkajwU8//QRfX98Ke+NcXV3h4+ODgwcPQqPRYMSIEWjZsiU2bdqEwYMH67WNiYlBr1690K1bNwDATz/9hGHDhsHPzw8bNmyASqXC1q1bERISgry8PEyZMkVv+5deeglPP/00vvjiC+Tm5sLc3LzS70+r1aKkpMRg/aPhLi0tDc899xzmzZuHZcuW4fvvv8fy5ctx7949fPTRRwCAgoICDBo0CH/99ReWLl2Kbt26ISEhAZGRkUhKSsL333+v29+UKVPw5ZdfYurUqVi2bBnkcjnOnj2L69ev631uVc7R8PBwfPHFF1i+fDl69uyJ3Nxc/Pbbb5X+vREZnUBERjV58mTByspKb92AAQMEAMKPP/5Y6bZarVYoLi4WDh8+LAAQzp07p3tv8eLFwqP/ybq7uwtKpVK4ceOGbl1+fr5gZ2cnvPLKK7p1P/30kwBA+Omnn/TqBCBs27ZNb5/Dhw8XOnXqpHu9bt06AYCwd+9evXavvPKKAEDYtGlTpcdU9tnbt2+vsM1zzz0nKBQKITk5WW99cHCwYGlpKdy/f18QBEEYMWKE0KNHj0o/r1mzZkJYWFilbR6VlpYmABCee+65StuFhIQIAITbt28LgiAI4eHhgoWFha4+QRCECxcuCACEtWvX6tZ5enoKPXv2FIqLi/X2N2LECMHZ2VnQaDSCIAjCpk2bBADCpEmTqlT3tWvXBAAVLgkJCbq2Zefgt99+q7ePl19+WZBKpbpzaMOGDeWeFytXrhQACPv37xcEQRCOHDkiABDmz59faY1VPUe9vb2F0aNHV+m4ieoKL58R1RNbW1s8+eSTBuuvXr2KCRMmwMnJCTKZDObm5hgwYAAA4OLFi4/db48ePeDm5qZ7rVQq0bFjR9y4ceOx20okEowcOVJvXbdu3fS2PXz4MKytrQ0GeT///POP3X9VHTx4EIMHD4arq6ve+ilTpiAvL083mL1Pnz44d+4cZs6ciX379kGtVhvsq0+fPoiJicHy5ctx4sQJFBcXG61OQRAAQHcZ86WXXkJ+fj7i4uJ0bTZt2gSFQqEb+Pznn3/i0qVLeOGFFwAAJSUlumX48OFITU3F5cuX9T5n3Lhx1arr9ddfx6lTpwyWHj166LWztrbGM888o7duwoQJ0Gq1OHLkCIDSvwsrKys8++yzeu3KerPKLhfu3bsXADBr1qzH1leVc7RPnz7Yu3cv5s2bh0OHDiE/P79qB09kRAxFRPXE2dnZYF1OTg4CAwPxyy+/YPny5Th06BBOnTqFnTt3AkCVfjG0aNHCYJ1CoajStpaWllAqlQbbFhQU6F5nZmbC0dHRYNvy1tVUZmZmud+Pi4uL7n0AiIiIwPvvv48TJ04gODgYLVq0wODBg3H69GndNnFxcZg8eTI++eQT+Pv7w87ODpMmTUJaWlqFn29vbw9LS0tcu3at0jqvX78OS0tL2NnZAQC6dOmC3r17Y9OmTQBKL8N9+eWXGDVqlK7N7du3AQBz586Fubm53jJz5kwAQEZGht7nlPddVKZ169bw9fU1WJo1a6bXrry/MycnJwAPv+PMzEw4OTkZjF9r2bIlzMzMdO3u3LkDmUym274yVTlH16xZg7feegvffPMNBg0aBDs7O4wePRpXrlx57P6JjIWhiKielHf30MGDB3Hr1i189tlnmDZtGvr37w9fX19YW1uLUGH5WrRoofvF/k+VhYyafEZqaqrB+lu3bgEoDS1A6RiZ8PBwnD17Fnfv3kVsbCxSUlIwdOhQ5OXl6dpGRUXh+vXruHHjBiIjI7Fz506DcTv/JJPJMGjQIJw+fRp///13uW3+/vtvnDlzBk8++SRkMplu/YsvvogTJ07g4sWL+OGHH5CamooXX3xR935Z7REREeX25pTXo1PT+agep7K/x7LgUvb3XdYrViY9PR0lJSW643FwcIBGozHaeWBlZYWlS5fi0qVLSEtLQ3R0NE6cOGHQk0lUlxiKiERU9stPoVDorf/444/FKKdcAwYMQHZ2tu5ySZmtW7ca7TMGDx6sC4j/tHnzZlhaWpZ7u3nz5s3x7LPPYtasWbh7967B4F6g9Fb12bNnY8iQITh79mylNUREREAQBMycOdPgbiyNRoNXX30VgiAgIiJC773nn38eSqUSMTExiImJQatWrRAUFKR7v1OnTujQoQPOnTtXbm9OfYbg7OxsgzvDtmzZAqlUqhvwPHjwYOTk5OCbb77Ra7d582bd+wAQHBwMoPROO2NzdHTElClT8Pzzz+Py5cu6wEtU13j3GZGIAgICYGtrixkzZmDx4sUwNzfHV199hXPnzoldms7kyZOxevVqTJw4EcuXL0f79u2xd+9e7Nu3DwB0d9E9zokTJ8pdP2DAACxevBjfffcdBg0ahEWLFsHOzg5fffUVvv/+e7z33ntQqVQAgJEjR8Lb2xu+vr5wcHDAjRs3EBUVBXd3d3To0AFZWVkYNGgQJkyYAE9PT1hbW+PUqVP44YcfMHbs2Err69evH6KiohAWFoYnnngCs2fPhpubm27yxl9++QVRUVEICAjQ26558+YYM2YMYmJicP/+fcydO9fgO/n4448RHByMoUOHYsqUKWjVqhXu3r2Lixcv4uzZs9i+fXuVvsOKJCcnl/v9Ojg4oF27drrXLVq0wKuvvork5GR07NgRe/bswf/+9z+8+uqrujE/kyZNwrp16zB58mRcv34dXbt2xdGjR/Huu+9i+PDheOqppwAAgYGBCA0NxfLly3H79m2MGDECCoUCiYmJsLS0xJw5c6p1DH5+fhgxYgS6desGW1tbXLx4EV988QX8/f2rNZ8XUa2IO86bqPGp6O6zLl26lNv+2LFjgr+/v2BpaSk4ODgI06ZNE86ePWtwZ1dFd589/fTTBvscMGCAMGDAAN3riu4+e7TOij4nOTlZGDt2rNCsWTPB2tpaGDdunLBnz55y72Z6VNlnV7SU1XT+/Hlh5MiRgkqlEuRyudC9e3eDO9s++OADISAgQLC3txfkcrng5uYmTJ06Vbh+/bogCIJQUFAgzJgxQ+jWrZtgY2MjWFhYCJ06dRIWL14s5ObmVlpnmePHjwvPPvus4OjoKJiZmQktW7YUxo4dKxw7dqzCbfbv3687nj/++KPcNufOnRPGjx8vtGzZUjA3NxecnJyEJ598UtiwYYOuTdndZ6dOnapSrY+7++yFF17QtS07Bw8dOiT4+voKCoVCcHZ2Fv773/8a3BWXmZkpzJgxQ3B2dhbMzMwEd3d3ISIiQigoKNBrp9FohNWrVwve3t6CXC4XVCqV4O/vL/zf//2frk1Vz9F58+YJvr6+gq2traBQKIS2bdsKb7zxhpCRkVGl74LIGCSC8MiFYyKiKnj33XexYMECJCcn83ESDcDAgQORkZGB3377TexSiEwWL58R0WOVTezn6emJ4uJiHDx4EGvWrMHEiRMZiIio0WAoIqLHsrS0xOrVq3H9+nUUFhbCzc0Nb731FhYsWCB2aURERsPLZ0RERETgLflEREREABiKiIiIiAAwFBEREREB4EDrcmm1Wty6dQvW1tZ1Nt0+ERERGZcgCMjOzoaLi0uVJ5b9J4aicty6dcvgad1ERETUMKSkpNRouhCGonKUPYcoJSUFNjY2IldDREREVaFWq+Hq6lrj5wkyFJWj7JKZjY0NQxEREVEDU9OhLxxoTURERASGIiIiIiIADEVEREREADimiIiITIhWq0VRUZHYZZAJk8vlNbrdvioYioiIyCQUFRXh2rVr0Gq1YpdCJkwqlcLDwwNyudzo+2YoIiIi0QmCgNTUVMhkMri6utZZTwA1bGWTK6empsLNzc3oEywzFBERkehKSkqQl5cHFxcXWFpail0OmTAHBwfcunULJSUlMDc3N+q+GcWJiEh0Go0GAOrkkgg1LmXnSNk5Y0wMRUREZDL4vEl6nLo8RxiKiIiIiMBQREREZFIGDhyIsLCwKre/fv06JBIJkpKS6qympoKhiIiIqAYkEkmly5QpU2q03507d+Ltt9+ucntXV1ekpqbC29u7Rp9XVU0hfPHus3okCAIycoqQU1gCD3srscshIqJaSE1N1f0cFxeHRYsW4fLly7p1FhYWeu2Li4urdLeUnZ1dteqQyWRwcnKq1jZUPtF7itavXw8PDw8olUr4+PggISGhStv9/PPPMDMzQ48ePQze27FjB7y8vKBQKODl5YVdu3YZueqaOXIlA73fOYBXvzwjdilERFRLTk5OukWlUkEikeheFxQUoHnz5ti2bRsGDhwIpVKJL7/8EpmZmXj++efRunVrWFpaomvXroiNjdXb76OXz9q0aYN3330XL730EqytreHm5oaNGzfq3n+0B+fQoUOQSCT48ccf4evrC0tLSwQEBOgFNgBYvnw5WrZsCWtra0ybNg3z5s0r93dqVRUWFuK1115Dy5YtoVQq8cQTT+DUqVO69+/du4cXXngBDg4OsLCwQIcOHbBp0yYApRN3zp49G87OzlAqlWjTpg0iIyNrXEtNiRqK4uLiEBYWhvnz5yMxMRGBgYEIDg5GcnJypdtlZWVh0qRJGDx4sMF7x48fR0hICEJDQ3Hu3DmEhoZi/Pjx+OWXX+rqMKqsVXMlAODm/XyRKyEiMm2CICCvqESURRAEox3HW2+9hddeew0XL17E0KFDUVBQAB8fH3z33Xf47bffMH36dISGhj72d9QHH3wAX19fJCYmYubMmXj11Vdx6dKlSreZP38+PvjgA5w+fRpmZmZ46aWXdO999dVXeOedd7By5UqcOXMGbm5uiI6OrtWxvvnmm9ixYwc+//xznD17Fu3bt8fQoUNx9+5dAMDChQtx4cIF7N27FxcvXkR0dDTs7e0BAGvWrMHu3buxbds2XL58GV9++SXatGlTq3pqQtTLZ6tWrcLUqVMxbdo0AEBUVBT27duH6OjoShPiK6+8ggkTJkAmk+Gbb77Rey8qKgpDhgxBREQEACAiIgKHDx9GVFSUQRqvby7NS7tSswtKoC4oho3SuJNOERE1FvnFGngt2ifKZ19YNhSWcuP8egwLC8PYsWP11s2dO1f385w5c/DDDz9g+/bt8PPzq3A/w4cPx8yZMwGUBq3Vq1fj0KFD8PT0rHCbd955BwMGDAAAzJs3D08//TQKCgqgVCqxdu1aTJ06FS+++CIAYNGiRdi/fz9ycnJqdJy5ubmIjo5GTEwMgoODAQD/+9//EB8fj08//RT/+c9/kJycjJ49e8LX1xcA9EJPcnIyOnTogCeeeAISiQTu7u41qqO2ROspKioqwpkzZxAUFKS3PigoCMeOHatwu02bNuGvv/7C4sWLy33/+PHjBvscOnRopfssLCyEWq3WW+qCpdwMtpalQegWe4uIiBq9sgBQRqPR4J133kG3bt3QokULNGvWDPv373/sFZJu3brpfi67TJeenl7lbZydnQFAt83ly5fRp08fvfaPvq6Ov/76C8XFxejXr59unbm5Ofr06YOLFy8CAF599VVs3boVPXr0wJtvvqn3e3nKlClISkpCp06d8Nprr2H//v01rqU2ROspysjIgEajgaOjo956R0dHpKWllbvNlStXMG/ePCQkJMDMrPzS09LSqrVPAIiMjMTSpUureQQ149LcAvfyinHrfj48nWzq5TOJiBoaC3MZLiwbKtpnG4uVlf5NNR988AFWr16NqKgodO3aFVZWVggLC0NRUVGl+3l0gLZEInnsg3P/uU3ZhIf/3ObRSRBrc9mwbNvy9lm2Ljg4GDdu3MD333+PAwcOYPDgwZg1axbef/999OrVC9euXcPevXtx4MABjB8/Hk899RS+/vrrGtdUE6IPtK7sC/wnjUaDCRMmYOnSpejYsaNR9lkmIiICWVlZuiUlJaUaR1A9rR5cQrt5v6DOPoOIqKGTSCSwlJuJstTljMkJCQkYNWoUJk6ciO7du6Nt27a4cuVKnX1eRTp16oSTJ0/qrTt9+nSN99e+fXvI5XIcPXpUt664uBinT59G586ddescHBwwZcoUfPnll4iKitIbMG5jY4OQkBD873//Q1xcHHbs2KEbj1RfROspsre3h0wmM+jBSU9PN+jpAYDs7GycPn0aiYmJmD17NoDSxCsIAszMzLB//348+eSTcHJyqvI+yygUCigUCiMc1eOVjSu6eY+Xz4iImpr27dtjx44dOHbsGGxtbbFq1SqkpaXpBYf6MGfOHLz88svw9fVFQEAA4uLi8Ouvv6Jt27aP3fbRu9gAwMvLC6+++ir+85//wM7ODm5ubnjvvfeQl5eHqVOnAigdt+Tj44MuXbqgsLAQ3333ne64V69eDWdnZ/To0QNSqRTbt2+Hk5MTmjdvbtTjfhzRQpFcLoePjw/i4+MxZswY3fr4+HiMGjXKoL2NjQ3Onz+vt279+vU4ePAgvv76a3h4eAAA/P39ER8fjzfeeEPXbv/+/QgICKijI6mesp4ijikiImp6Fi5ciGvXrmHo0KGwtLTE9OnTMXr0aGRlZdVrHS+88AKuXr2KuXPnoqCgAOPHj8eUKVMMeo/K89xzzxmsu3btGlasWAGtVovQ0FBkZ2fD19cX+/btg62tLYDS3/sRERG4fv06LCwsEBgYiK1btwIAmjVrhpUrV+LKlSuQyWTo3bs39uzZA6m0ni9oCSLaunWrYG5uLnz66afChQsXhLCwMMHKykq4fv26IAiCMG/ePCE0NLTC7RcvXix0795db93PP/8syGQyYcWKFcLFixeFFStWCGZmZsKJEyeqXFdWVpYAQMjKyqrRcVXm+19vCe5vfSeMW/+z0fdNRNRQ5efnCxcuXBDy8/PFLqXJeuqpp4SJEyeKXcZjVXau1Pb3t6i35IeEhCAzMxPLli3TTVG+Z88e3a14qampjx2R/6iAgABs3boVCxYswMKFC9GuXTvExcVVeqtjfdJdPmNPERERiSQvLw8bNmzA0KFDIZPJEBsbiwMHDiA+Pl7s0kQlEQQjzlLVSKjVaqhUKmRlZcHGxrh3iKVnF6DPOz9CKgEuLw+GuUz0se5ERKIrKCjAtWvXdE84oLqVn5+PkSNH4uzZsygsLESnTp2wYMECgzmVTFFl50ptf3/z2Wf1zN5KAbmZFEUlWtxWF6C1raXYJRERURNjYWGBAwcOiF2GyWE3RT2TSiVwUT143AfvQCMiIjIZDEUiKBtXdCuLoYiI6J84ooMepy7PEYYiEehCESdwJCICAMhkpbNIP25mZ6Kyc6TsnDEmjikSQdlcRX/z8hkREQDAzMwMlpaWuHPnDszNzet/fhpqELRaLe7cuQNLS8sKH/dVGwxFIuAEjkRE+iQSCZydnXHt2jXcuHFD7HLIhEmlUri5udXJ41gYikTgwlBERGRALpejQ4cOvIRGlZLL5XXWk8hQJIJWtg9DkfCYh9USETUlUqmU8xSRaHjRVgTOD27Jzy3SICu/WORqiIiICGAoEoXSXAb7ZnIAfNwHERGRqWAoEkkr3pZPRERkUhiKRKJ7MOy9PJErISIiIoChSDQPZ7VmTxEREZEpYCgSSdnlM44pIiIiMg0MRSJ5ePmMoYiIiMgUMBSJhLNaExERmRaGIpG4NC+dqyg9uxCFJRqRqyEiIiKGIpHYWcmhNC/9+tM42JqIiEh0DEUikUgkD8cV8RIaERGR6BiKRMQJHImIiEwHQ5GIWvEONCIiIpPBUCQiF96BRkREZDIYikT0cFZrhiIiIiKxMRSJiLNaExERmQ6GIhH9cwJHQRBEroaIiKhpYygSkZNKCYkEKCjW4m5ukdjlEBERNWkMRSKSm0nR0loBgLflExERiY2hSGQPJ3DME7kSIiKipo2hSGQPQxF7ioiIiMTEUCSy1pyriIiIyCSIHorWr18PDw8PKJVK+Pj4ICEhocK2R48eRb9+/dCiRQtYWFjA09MTq1ev1msTExMDiURisBQUmGZPjAtntSYiIjIJZmJ+eFxcHMLCwrB+/Xr069cPH3/8MYKDg3HhwgW4ubkZtLeyssLs2bPRrVs3WFlZ4ejRo3jllVdgZWWF6dOn69rZ2Njg8uXLetsqlco6P56a4ASOREREpkHUULRq1SpMnToV06ZNAwBERUVh3759iI6ORmRkpEH7nj17omfPnrrXbdq0wc6dO5GQkKAXiiQSCZycnOr+AIzApXlpWOPlMyIiInGJdvmsqKgIZ86cQVBQkN76oKAgHDt2rEr7SExMxLFjxzBgwAC99Tk5OXB3d0fr1q0xYsQIJCYmGq1uY2vd3BIAkJFThIJijcjVEBERNV2ihaKMjAxoNBo4OjrqrXd0dERaWlql27Zu3RoKhQK+vr6YNWuWrqcJADw9PRETE4Pdu3cjNjYWSqUS/fr1w5UrVyrcX2FhIdRqtd5SX2wszGAllwFgbxEREZGYRB9oLZFI9F4LgmCw7lEJCQk4ffo0NmzYgKioKMTGxure69u3LyZOnIju3bsjMDAQ27ZtQ8eOHbF27doK9xcZGQmVSqVbXF1da3dQ1SCRSB6OK+Jt+URERKIRLRTZ29tDJpMZ9Aqlp6cb9B49ysPDA127dsXLL7+MN954A0uWLKmwrVQqRe/evSvtKYqIiEBWVpZuSUlJqdax1FYrW96WT0REJDbRQpFcLoePjw/i4+P11sfHxyMgIKDK+xEEAYWFhZW+n5SUBGdn5wrbKBQK2NjY6C31qayn6G+GIiIiItGIevdZeHg4QkND4evrC39/f2zcuBHJycmYMWMGgNIenJs3b2Lz5s0AgHXr1sHNzQ2enp4ASuctev/99zFnzhzdPpcuXYq+ffuiQ4cOUKvVWLNmDZKSkrBu3br6P8AqasUJHImIiEQnaigKCQlBZmYmli1bhtTUVHh7e2PPnj1wd3cHAKSmpiI5OVnXXqvVIiIiAteuXYOZmRnatWuHFStW4JVXXtG1uX//PqZPn460tDSoVCr07NkTR44cQZ8+fer9+KqKoYiIiEh8EkEQBLGLMDVqtRoqlQpZWVn1cint5LW7GP/xcbi3sMTh/wyq888jIiJqjGr7+1v0u8/o4QSOqfcLoNUyoxIREYmBocgEONkoIZUARRotMnIrHjROREREdYehyASYyaRwsintLeKDYYmIiMTBUGQiOIEjERGRuBiKTIQL70AjIiISFUORiSib1fomQxEREZEoGIpMRFlPEUMRERGROBiKTESrB7fl8/IZERGROBiKTESr5pYA2FNEREQkFoYiE1E2geP9vGLkFpaIXA0REVHTw1BkIqyV5rBWlj6KLjWLvUVERET1jaHIhLTSDbbmXEVERET1jaHIhOhCEWe1JiIiqncMRSaEEzgSERGJh6HIhJRN4MhQREREVP8YikxIWU/R3wxFRERE9Y6hyIRwAkciIiLxMBSZkLKeorSsAmi0gsjVEBERNS0MRSakpbUSZlIJSrQC0rN5Wz4REVF9YigyITKpBE4qXkIjIiISA0ORiXHhBI5ERESiYCgyMa05gSMREZEoGIpMDCdwJCIiEgdDkYlhKCIiIhIHQ5GJKZvV+iZDERERUb1iKDIxZRM4MhQRERHVL4YiE1N2+Sy7oATqgmKRqyEiImo6GIpMjKXcDLaW5gCAVN6WT0REVG8YikzQw7mK8kSuhIiIqOlgKDJBnMCRiIio/jEUmaBWvC2fiIio3okeitavXw8PDw8olUr4+PggISGhwrZHjx5Fv3790KJFC1hYWMDT0xOrV682aLdjxw54eXlBoVDAy8sLu3btqstDMLpWnNWaiIio3okaiuLi4hAWFob58+cjMTERgYGBCA4ORnJycrntraysMHv2bBw5cgQXL17EggULsGDBAmzcuFHX5vjx4wgJCUFoaCjOnTuH0NBQjB8/Hr/88kt9HVatcQJHIiKi+icRBEEQ68P9/PzQq1cvREdH69Z17twZo0ePRmRkZJX2MXbsWFhZWeGLL74AAISEhECtVmPv3r26NsOGDYOtrS1iY2OrtE+1Wg2VSoWsrCzY2NhU44iMIzH5HsasPwYXlRLHIgbX++cTERE1RLX9/S1aT1FRURHOnDmDoKAgvfVBQUE4duxYlfaRmJiIY8eOYcCAAbp1x48fN9jn0KFDK91nYWEh1Gq13iKmslmt09QFKNZoRa2FiIioqRAtFGVkZECj0cDR0VFvvaOjI9LS0irdtnXr1lAoFPD19cWsWbMwbdo03XtpaWnV3mdkZCRUKpVucXV1rcERGY+9lQJymRRaAbit5h1oRERE9UH0gdYSiUTvtSAIBuselZCQgNOnT2PDhg2IiooyuCxW3X1GREQgKytLt6SkpFTzKIxLKpXA+cHjPm7xtnwiIqJ6YSbWB9vb20Mmkxn04KSnpxv09DzKw8MDANC1a1fcvn0bS5YswfPPPw8AcHJyqvY+FQoFFApFTQ6jzrRqboEbmXkcbE1ERFRPROspksvl8PHxQXx8vN76+Ph4BAQEVHk/giCgsLBQ99rf399gn/v376/WPk3BwwkcGYqIiIjqg2g9RQAQHh6O0NBQ+Pr6wt/fHxs3bkRycjJmzJgBoPSy1s2bN7F582YAwLp16+Dm5gZPT08ApfMWvf/++5gzZ45un6+//jr69++PlStXYtSoUfj2229x4MABHD16tP4PsBYYioiIiOqXqKEoJCQEmZmZWLZsGVJTU+Ht7Y09e/bA3d0dAJCamqo3Z5FWq0VERASuXbsGMzMztGvXDitWrMArr7yiaxMQEICtW7diwYIFWLhwIdq1a4e4uDj4+fnV+/HVRmvOVURERFSvRJ2nyFSJPU8RABy9koGJn/6CDi2bIT58wOM3ICIiauIa7DxFVDkX3d1n+WBuJSIiqnsMRSaqbExRbpEG6vwSkashIiJq/BiKTJTSXAb7ZnIAwN/380SuhoiIqPFjKDJhDx8MywkciYiI6hpDkQlzUfEONCIiovrCUGTCyh4My7mKiIiI6h5DkQnjBI5ERET1h6HIhLX6x235REREVLcYikxYq+aWAICb9xiKiIiI6hpDkQkrm8AxPbsQhSUakashIiJq3BiKTJidlRxK89K/ottZhSJXQ0RE1LgxFJkwiUTCwdZERET1hKHIxLViKCIiIqoXDEUmjhM4EhER1Q+GIhNXNoEjQxEREVHdYigycRxTREREVD8Yikxc2W35DEVERER1i6HIxJUNtL51Px+CIIhcDRERUePFUGTinFRKSCRAQbEWd3OLxC6HiIio0WIoMnEKMxkcmikAALfuF4hcDRERUePFUNQAcLA1ERFR3WMoagDKbstnKCIiIqo7DEUNwD8HWxMREVHdYChqAFxUpbflMxQRERHVHYaiBqCVrSUAhiIiIqK6xFDUAHACRyIiorrHUNQAlI0pysgpQkGxRuRqiIiIGieGogZAZWEOK7kMAJCaxbmKiIiI6gJDUQMgkUgezlV0j5fQiIiI6gJDUQPhwtvyiYiI6hRDUQPBWa2JiIjqluihaP369fDw8IBSqYSPjw8SEhIqbLtz504MGTIEDg4OsLGxgb+/P/bt26fXJiYmBhKJxGApKGjYY3Fac1ZrIiKiOiVqKIqLi0NYWBjmz5+PxMREBAYGIjg4GMnJyeW2P3LkCIYMGYI9e/bgzJkzGDRoEEaOHInExES9djY2NkhNTdVblEplfRxSnSm7LZ+Xz4iIiOqGmZgfvmrVKkydOhXTpk0DAERFRWHfvn2Ijo5GZGSkQfuoqCi91++++y6+/fZb/N///R969uypWy+RSODk5FSntdc3FxXHFBEREdUl0XqKioqKcObMGQQFBemtDwoKwrFjx6q0D61Wi+zsbNjZ2emtz8nJgbu7O1q3bo0RI0YY9CQ9qrCwEGq1Wm8xNWUPhb11vwBarSByNURERI2PaKEoIyMDGo0Gjo6OeusdHR2RlpZWpX188MEHyM3Nxfjx43XrPD09ERMTg927dyM2NhZKpRL9+vXDlStXKtxPZGQkVCqVbnF1da3ZQdUhRxslpBKgSKNFRm6h2OUQERE1OqIPtJZIJHqvBUEwWFee2NhYLFmyBHFxcWjZsqVufd++fTFx4kR0794dgYGB2LZtGzp27Ii1a9dWuK+IiAhkZWXplpSUlJofUB0xl0nhaFM2rqhhDxonIiIyRaKNKbK3t4dMJjPoFUpPTzfoPXpUXFwcpk6diu3bt+Opp56qtK1UKkXv3r0r7SlSKBRQKBRVL14krZpbIDWrADfv5aOHa3OxyyEiImpUROspksvl8PHxQXx8vN76+Ph4BAQEVLhdbGwspkyZgi1btuDpp59+7OcIgoCkpCQ4OzvXumaxcQJHIiKiuiPq3Wfh4eEIDQ2Fr68v/P39sXHjRiQnJ2PGjBkASi9r3bx5E5s3bwZQGogmTZqEDz/8EH379tX1MllYWEClUgEAli5dir59+6JDhw5Qq9VYs2YNkpKSsG7dOnEO0og4gSMREVHdETUUhYSEIDMzE8uWLUNqaiq8vb2xZ88euLu7AwBSU1P15iz6+OOPUVJSglmzZmHWrFm69ZMnT0ZMTAwA4P79+5g+fTrS0tKgUqnQs2dPHDlyBH369KnXY6sLD+9AYygiIiIyNokgCLy/+xFqtRoqlQpZWVmwsbERuxydg5du46WY0+jiYoPvXwsUuxwiIiKTUtvf36LffUZVxzFFREREdYehqAEpC0X38oqRV1QicjVERESNC0NRA2KjNIe1snQYGHuLiIiIjIuhqIFppbsDjRM4EhERGRNDUQPDcUVERER1g6GogdH1FN1jKCIiIjImhqIGhj1FREREdYOhqIFxaV76UFjOak1ERGRcDEUNTGtbPuqDiIioLjAUNTBll8/Ssgqg0XIyciIiImNhKGpgWlorYSaVoEQr4E52odjlEBERNRoMRQ2MTCqBk4rjioiIiIyNoagBcmnOcUVERETGxlDUALXibflERERGx1DUADEUERERGR9DUQPkwlmtiYiIjI6hqAHiBI5ERETGx1DUAPHyGRERkfExFDVAZZfP1AUlyC4oFrkaIiKixoGhqAGyUpihuaU5AODW/QKRqyEiImocGIoaKBcVL6EREREZU41CUUpKCv7++2/d65MnTyIsLAwbN240WmFUuVYPHgz7N0MRERGRUdQoFE2YMAE//fQTACAtLQ1DhgzByZMn8d///hfLli0zaoFUPg62JiIiMq4ahaLffvsNffr0AQBs27YN3t7eOHbsGLZs2YKYmBhj1kcVKAtFyXfzRK6EiIiocahRKCouLoZCoQAAHDhwAM888wwAwNPTE6mpqcarjirUwbEZAOByWrbIlRARETUONQpFXbp0wYYNG5CQkID4+HgMGzYMAHDr1i20aNHCqAVS+bxcbAAAV+/kIL9II3I1REREDV+NQtHKlSvx8ccfY+DAgXj++efRvXt3AMDu3bt1l9WobrW0VsK+mQJaAbh8m71FREREtWVWk40GDhyIjIwMqNVq2Nra6tZPnz4dlpaWRiuOKuflYoMjf9zBhVtq9HBtLnY5REREDVqNeory8/NRWFioC0Q3btxAVFQULl++jJYtWxq1QKqYl3PpJbQLqVkiV0JERNTw1SgUjRo1Cps3bwYA3L9/H35+fvjggw8wevRoREdHG7VAqljZuKILt9QiV0JERNTw1SgUnT17FoGBgQCAr7/+Go6Ojrhx4wY2b96MNWvWVGtf69evh4eHB5RKJXx8fJCQkFBh2507d2LIkCFwcHCAjY0N/P39sW/fPoN2O3bsgJeXFxQKBby8vLBr167qHWADUdZTdDE1GxqtIHI1REREDVuNQlFeXh6sra0BAPv378fYsWMhlUrRt29f3Lhxo8r7iYuLQ1hYGObPn4/ExEQEBgYiODgYycnJ5bY/cuQIhgwZgj179uDMmTMYNGgQRo4cicTERF2b48ePIyQkBKGhoTh37hxCQ0Mxfvx4/PLLLzU5VJPmYW8FpbkU+cUaXM/MFbscIiKiBk0iCEK1uxi6deuGadOmYcyYMfD29sYPP/wAf39/nDlzBk8//TTS0tKqtB8/Pz/06tVL75Jb586dMXr0aERGRlZpH126dEFISAgWLVoEAAgJCYFarcbevXt1bYYNGwZbW1vExsZWaZ9qtRoqlQpZWVmwsbGp0jZiGb3uZySl3Mfa53tiZHcXscshIiISTW1/f9eop2jRokWYO3cu2rRpgz59+sDf3x9Aaa9Rz549q7SPoqIinDlzBkFBQXrrg4KCcOzYsSrtQ6vVIjs7G3Z2drp1x48fN9jn0KFDK91nYWEh1Gq13tJQdCkbV5TacGomIiIyRTUKRc8++yySk5Nx+vRpvTE9gwcPxurVq6u0j4yMDGg0Gjg6Ouqtd3R0rHJP0wcffIDc3FyMHz9ety4tLa3a+4yMjIRKpdItrq6uVfp8U8DB1kRERMZRo1AEAE5OTujZsydu3bqFmzdvAgD69OkDT0/Pau1HIpHovRYEwWBdeWJjY7FkyRLExcUZTANQ3X1GREQgKytLt6SkpFTjCMT18LZ8hiIiIqLaqFEo0mq1WLZsGVQqFdzd3eHm5obmzZvj7bffhlarrdI+7O3tIZPJDHpw0tPTDXp6HhUXF4epU6di27ZteOqpp/Tec3JyqvY+FQoFbGxs9JaGwtPJBlIJcCe7EOnZBWKXQ0RE1GDVKBTNnz8fH330EVasWIHExEScPXsW7777LtauXYuFCxdWaR9yuRw+Pj6Ij4/XWx8fH4+AgIAKt4uNjcWUKVOwZcsWPP300wbv+/v7G+xz//79le6zIbOQy+BhbwWg9NZ8IiIiqpkaPebj888/xyeffIJnnnlGt6579+5o1aoVZs6ciXfeeadK+wkPD0doaCh8fX3h7++PjRs3Ijk5GTNmzABQelnr5s2buokiY2NjMWnSJHz44Yfo27evrkfIwsICKpUKAPD666+jf//+WLlyJUaNGoVvv/0WBw4cwNGjR2tyqA2Cl4sKf93JxYVbagzo6CB2OURERA1SjXqK7t69W+7YIU9PT9y9e7fK+wkJCUFUVBSWLVuGHj164MiRI9izZw/c3d0BAKmpqXpzFn388ccoKSnBrFmz4OzsrFtef/11XZuAgABs3boVmzZtQrdu3RATE4O4uDj4+fnV5FAbBI4rIiIiqr0azVPk5+cHPz8/g9mr58yZg5MnTzb4iRIb0jxFAHD4jzuY/NlJtHOwwo//Hih2OURERKKo7e/vGl0+e++99/D000/jwIED8Pf3h0QiwbFjx5CSkoI9e/bUZJdUC2U9RVczcpFXVAJLeY3+WomIiJq0Gl0+GzBgAP744w+MGTMG9+/fx927dzF27Fj8/vvv2LRpk7FrpMdwsFbAwVoBQQAupXGwNRERUU3U6PJZRc6dO4devXpBo9EYa5eiaGiXzwBg8mcncfiPO1g+2hsT+7qLXQ4REVG9E+UxH2R6vPi4DyIiolphKGokdHeg8XEfRERENcJQ1EiUPRj2UpoaGq3RrogSERE1GdW6TWns2LGVvn///v3a1EK14N7CCpZyGfKKNLiWkYv2LZuJXRIREVGDUq1QVDZrdGXvT5o0qVYFUc3IpBJ4OlnjbPJ9XEhVMxQRERFVU7VCEW+3N21eLjaloeiWGs90dxG7HCIiogaFY4oaES/n0p483oFGRERUfQxFjYjutnzegUZERFRtDEWNSCdHa0glQEZOIdKzC8Quh4iIqEFhKGpELOQytHUoHWDN3iIiIqLqYShqZMomcfydoYiIiKhaGIoaGT7ug4iIqGYYihqZsp6ii+wpIiIiqhaGokamrKfoWmYucgtLRK6GiIio4WAoamTsmyngaKOAIACX0rLFLoeIiKjBYChqhMouoXFcERERUdUxFDVCnMSRiIio+hiKGiE+7oOIiKj6GIoaobKeokupapRotCJXQ0RE1DAwFDVC7naWsJTLUFiixfXMXLHLISIiahAYihohqVSCzpzZmoiIqFoYihop3oFGRERUPQxFjRTvQCMiIqoehqJGStdTdEsNQRBEroaIiMj0MRQ1Up2crCGVAJm5RUjPLhS7HCIiIpPHUNRIKc1laOfQDAAvoREREVUFQ1Ej1sWFg62JiIiqiqGoEeNgayIioqoTPRStX78eHh4eUCqV8PHxQUJCQoVtU1NTMWHCBHTq1AlSqRRhYWEGbWJiYiCRSAyWgoKCOjwK08THfRAREVWdqKEoLi4OYWFhmD9/PhITExEYGIjg4GAkJyeX276wsBAODg6YP38+unfvXuF+bWxskJqaqrcolcq6OgyT1dnZGgBwPTMXOYUlIldDRERk2kQNRatWrcLUqVMxbdo0dO7cGVFRUXB1dUV0dHS57du0aYMPP/wQkyZNgkqlqnC/EokETk5OektT1KKZAk42SggCcDmNvUVERESVES0UFRUV4cyZMwgKCtJbHxQUhGPHjtVq3zk5OXB3d0fr1q0xYsQIJCYmVtq+sLAQarVab2ksOK6IiIioakQLRRkZGdBoNHB0dNRb7+joiLS0tBrv19PTEzExMdi9ezdiY2OhVCrRr18/XLlypcJtIiMjoVKpdIurq2uNP9/U8HEfREREVSP6QGuJRKL3WhAEg3XV0bdvX0ycOBHdu3dHYGAgtm3bho4dO2Lt2rUVbhMREYGsrCzdkpKSUuPPNzXsKSIiIqoaM7E+2N7eHjKZzKBXKD093aD3qDakUil69+5daU+RQqGAQqEw2meakrKeoktp2SjRaGEmEz0HExERmSTRfkPK5XL4+PggPj5eb318fDwCAgKM9jmCICApKQnOzs5G22dD4mZnCSu5DIUlWlzNyBW7HCIiIpMlWk8RAISHhyM0NBS+vr7w9/fHxo0bkZycjBkzZgAovax18+ZNbN68WbdNUlISgNLB1Hfu3EFSUhLkcjm8vLwAAEuXLkXfvn3RoUMHqNVqrFmzBklJSVi3bl29H58pkEol6Oxsg9M37uHCLTU6OlqLXRIREZFJEjUUhYSEIDMzE8uWLUNqaiq8vb2xZ88euLu7AyidrPHROYt69uyp+/nMmTPYsmUL3N3dcf36dQDA/fv3MX36dKSlpUGlUqFnz544cuQI+vTpU2/HZWq8XB6EolQ1RvdsJXY5REREJkkiCIIgdhGmRq1WQ6VSISsrCzY2NmKXU2txp5Lx1o7zeKK9Pb6c5id2OURERHWitr+/Oeq2Cfjn4z6YgYmIiMrHUNQEdHBsBplUgru5RbitLhS7HCIiIpPEUNQEKM1laO/QDABwITVL5GqIiIhME0NRE8FJHImIiCrHUNRE8HEfRERElWMoaiLYU0RERFQ5hqImovODnqLrmXnIKSwRuRoiIiLTw1DURNhZyeGsUgIALvISGhERkQGGoiZEN66Il9CIiIgMMBQ1IRxXREREVDGGoiaEd6ARERFVjKGoCSnrKbp8OxvFGq3I1RAREZkWhqImxNXWEtYKMxSVaHH1Tq7Y5RAREZkUhqImRCqV6G7N5+M+iIiI9DEUNTEcbE1ERFQ+hqImhoOtiYiIysdQ1MT8s6dIEASRqyEiIjIdDEVNTPuWzWAmleBeXjHS1AVil0NERGQyGIqaGKW5DO1bNgPAcUVERET/xFDUBJWNK/qdoYiIiEiHoagJ4h1oREREhhiKmiDegUZERGSIoagJKpvAMfluHtQFxSJXQ0REZBoYipogWys5XFRKAMCl1GyRqyEiIjINDEVNlJeLCgBw4RYf90FERAQwFDVZusHWHFdEREQEgKGoyeJgayIiIn0MRU1Ulwc9RX+k5aBYoxW5GiIiIvExFDVRrW0tYK0wQ5FGi7/u5IhdDhERkegYipooiUSCzpzEkYiISEf0ULR+/Xp4eHhAqVTCx8cHCQkJFbZNTU3FhAkT0KlTJ0ilUoSFhZXbbseOHfDy8oJCoYCXlxd27dpVR9U3bLpxRQxFRERE4oaiuLg4hIWFYf78+UhMTERgYCCCg4ORnJxcbvvCwkI4ODhg/vz56N69e7ltjh8/jpCQEISGhuLcuXMIDQ3F+PHj8csvv9TloTRIvAONiIjoIYkgCIJYH+7n54devXohOjpat65z584YPXo0IiMjK9124MCB6NGjB6KiovTWh4SEQK1WY+/evbp1w4YNg62tLWJjY6tUl1qthkqlQlZWFmxsbKp+QA3MbzezMGLtUagszJG0aAgkEonYJREREdVYbX9/i9ZTVFRUhDNnziAoKEhvfVBQEI4dO1bj/R4/ftxgn0OHDq3VPhurDo7NYCaVICu/GLeyCsQuh4iISFSihaKMjAxoNBo4OjrqrXd0dERaWlqN95uWllbtfRYWFkKtVustTYHCTIb2LZsB4LgiIiIi0QdaP3rJRhCEWl/Gqe4+IyMjoVKpdIurq2utPr8h8eIdaERERABEDEX29vaQyWQGPTjp6ekGPT3V4eTkVO19RkREICsrS7ekpKTU+PMbmi5lz0BL5TPQiIioaRMtFMnlcvj4+CA+Pl5vfXx8PAICAmq8X39/f4N97t+/v9J9KhQK2NjY6C1NBR/3QUREVMpMzA8PDw9HaGgofH194e/vj40bNyI5ORkzZswAUNqDc/PmTWzevFm3TVJSEgAgJycHd+7cQVJSEuRyOby8vAAAr7/+Ovr374+VK1di1KhR+Pbbb3HgwAEcPXq03o+vISgLRSl385GVXwyVhbnIFREREYlD1FAUEhKCzMxMLFu2DKmpqfD29saePXvg7u4OoHSyxkfnLOrZs6fu5zNnzmDLli1wd3fH9evXAQABAQHYunUrFixYgIULF6Jdu3aIi4uDn59fvR1XQ6KyNEer5ha4eT8fl1LV8GvbQuySiIiIRCHqPEWmqqnMU1Tm5c2nEX/hNuYGdcTsJzuIXQ4REVGNNNh5ish0DPEqHYS+/czf0GqZkYmIqGliKCKM6OYMa4UZbmTm4fjVTLHLISIiEgVDEcFSbobRPVsBALb8Uv5z54iIiBo7hiICADzfxw0AsO/3NNzJLhS5GiIiovrHUEQASme27u7aHCVaATvO/i12OURERPWOoYh0XnjQW7T1ZDIHXBMRUZPDUEQ6I7o7o5nCDNcz83CCA66JiKiJYSgindIB1y4AgK9OcsA1ERE1LQxFpKdswPX+39OQkcMB10RE1HQwFJGeLi4qdG+tQrFGwI4zHHBNRERNB0MRGZjgV9pbFHsyGXwKDBERNRUMRWRgRDcX3YBrznBNRERNBUMRGbBSmGFUj9IB15zhmoiImgqGIirXP2e4zuSAayIiagIYiqhc3q1U6FY24JozXBMRURPAUEQVmtCnbMB1CgdcExFRo8dQRBUa2d0FVnIZrmXk4sTVu2KXQ0REVKcYiqhCVgozjOrZCgCwhTNcExFRI8dQRJUqu4S27zcOuCYiosaNoYgq5d1Kha6tVCjSaLHz7E2xyyEiIqozDEX0WJzhmoiImgKGInqssgHXVzNy8cs1DrgmIqLGiaGIHquZwgzP9Hgw4JozXBMRUSPFUERVUjbg+off0nA3t0jkaoiIiIyPoYiqpGtrFbxb2TwYcM0ZromIqPFhKKIqm9DHHUDpnEUccE1ERI0NQxFV2TM9XGApl+HqnVyc5IBrIiJqZBiKqMqaKcwwqocLAM5wTUREjQ9DEVXL8w8GXO89n4Z7HHBNRESNCEMRVUvXVip0cSkdcL2DA66JiKgRYSiiapFIJJzhmoiIGiXRQ9H69evh4eEBpVIJHx8fJCQkVNr+8OHD8PHxgVKpRNu2bbFhwwa992NiYiCRSAyWgoKCujyMJuWZ7qUDrv+6k4tT1++JXQ4REZFRiBqK4uLiEBYWhvnz5yMxMRGBgYEIDg5GcnL5g3ivXbuG4cOHIzAwEImJifjvf/+L1157DTt27NBrZ2Njg9TUVL1FqVTWxyE1CdZKczzT/cGA619uiFwNERGRcYgailatWoWpU6di2rRp6Ny5M6KiouDq6oro6Ohy22/YsAFubm6IiopC586dMW3aNLz00kt4//339dpJJBI4OTnpLWRcZQOu9/zGAddERNQ4iBaKioqKcObMGQQFBemtDwoKwrFjx8rd5vjx4wbthw4ditOnT6O4uFi3LicnB+7u7mjdujVGjBiBxMTESmspLCyEWq3WW6hy3Vqr4OVsg6ISLXYm3hS7HCIioloTLRRlZGRAo9HA0dFRb72joyPS0tLK3SYtLa3c9iUlJcjIyAAAeHp6IiYmBrt370ZsbCyUSiX69euHK1euVFhLZGQkVCqVbnF1da3l0TV+HHBNRESNjegDrSUSid5rQRAM1j2u/T/X9+3bFxMnTkT37t0RGBiIbdu2oWPHjli7dm2F+4yIiEBWVpZuSUlJqenhNCmjerjAwlyGP9NzcPoGB1wTEVHDJloosre3h0wmM+gVSk9PN+gNKuPk5FRuezMzM7Ro0aLcbaRSKXr37l1pT5FCoYCNjY3eQo+nP+CaM1wTEVHDJlooksvl8PHxQXx8vN76+Ph4BAQElLuNv7+/Qfv9+/fD19cX5ubm5W4jCAKSkpLg7OxsnMJJz/MPLqF9fz4V9/M44JqIiBouUS+fhYeH45NPPsFnn32Gixcv4o033kBycjJmzJgBoPSy1qRJk3TtZ8yYgRs3biA8PBwXL17EZ599hk8//RRz587VtVm6dCn27duHq1evIikpCVOnTkVSUpJun2Rc3Vur0LlswPVZDrgmIqKGy0zMDw8JCUFmZiaWLVuG1NRUeHt7Y8+ePXB3dwcApKam6s1Z5OHhgT179uCNN97AunXr4OLigjVr1mDcuHG6Nvfv38f06dORlpYGlUqFnj174siRI+jTp0+9H19TUDbgeuE3vyH2ZDJe7Nem0jFhREREpkoi8LYhA2q1GiqVCllZWRxfVAXqgmL4vfMj8os1+HqGP3zb2IldEhERNUG1/f0t+t1n1PDZKM0xsnvpmC0OuCYiooaKoYiMomyG6+844JqIiBoohiIyih6uzXUDrndxhmsiImqAGIrIKCQSCSb0KZ0JfMsvnOGaiIgaHoYiMppRPVtBaS7FlfQchH56En+m54hdEhERUZUxFJHR2CjNsWRkF8jNpDj6ZwaCPzyClT9cQl5RidilERERPRZDERnVc33ccOCNAXjSsyWKNQKiD/2Fpz44jL3nU3lJjYiITBpDERmdWwtLfDalNz6Z5IvWtha4lVWAV786i0mfncTVO7ykRkREpomhiOrMU16OOBA+AK8N7gC5mRQJVzIwNOoI/t8+XlIjIiLTw1BEdUppLkP4kI7YH9YfAzs5oFgjYN1Pf2HIqiP44bc0XlIjIiKTwVBE9aKNvRU2TemNjaE+aNXcAjfv52PGl2cwZdMpXMvIFbs8IiIihiKqPxKJBEFdnHAgfADmPNkecpkUh/+4g6Grj+CD/ZeRX6QRu0QiImrCGIqo3lnIZfh3UCfse6M/+nd0QJFGi7UH/8RTqw5j/++8pEZEROJgKCLReNhb4fMXe2PDxIeX1KZ/cQYvxZzCdV5Sa/CSM/Mwa8tZfHr0Gko0WrHLISJ6LInA/y03oFaroVKpkJWVBRsbG7HLaRLyikqw7qc/sfHIVRRrBMhlUswY0BavDmwPC7lM7PKomi7cUmPyppO4k10IAOjiYoPIsV3RrXVzcQsjokattr+/GYrKwVAknr/u5GDJ7t+RcCVDt05lYQ47KznsrOSwtZTDzsocdlYKvT9tLeVoYaWArZU5minMIJFIRDyKpu3ktbuY+vkpZBeUoK2DFTJzipCVXwypBJgS4IF/B3WElcJM7DKJqBFiKKoDDEXiEgQBP/yWhuXfX8TN+/nV3l4uk8K2LCg1kz8ITHI0U5rBUm4GS7nswWKm96eVQgYLuRms5DJYyGWQy6QMV9UUf+E2Zm85i8ISLfq0scP/JvuiWKPF299dwLdJtwAALiollo3yxlNejiJXS0SNDUNRHWAoMg1arYB7eUW4m1u63MsrQmZuEe7lPvzzbl4x7uYW4l5uMTJzC1FQbLyxK2ZSCSzkMliVhSeFDJbmZrBSyODc3AKutpZwtbOAm50lXG0t0dzSvEmHqO2nUzBv53lotAKe6twSH03oBaX5w0ufh/+4gwXfnEfK3dKgG+zthCXPdIGjjVKskomokWEoqgMMRQ1XfpEGmQ9C0t28ItzNLcTd3NLglFuoQV5RCXKLNMgv0iC3sAT5xQ/+LNLo1hfVcFBwM4UZXO0s4WprofvTrUVpYGpta1lnY6MEQUB+sQZymRRmMnHunfj48F+I3HsJAPCsT2usGNu13FryizSI+vEPfJJwDRqtAGuFGd4M9sQLfdwglTbdQElExsFQVAcYipq2Yo0WeWXBqahEF6DyijXIK9Qgu6AYt+7nI/luHlLu5SPlbh7SHwworoyDteIfgckSbnaWcLBRoLBYi/ziEt1n5j1Y8oserCv+x/rif6wva1dcOr9Tc0tzzA3qhAn1GDAEQUDk3kvYeOQqAOCV/m0xL9jzsT1mF26pEbHrPM6l3AcA9HJrjsix3dDJybquSyaiRoyhqA4wFFF1FRRr8Pe9PKTcfRCW7uYh5cHrlLt5yC6sv2e9dXdtjndGe8O7lapOP6dEo8W8nefx9Zm/AQARwZ54ZUC7Km+v0Qr44vh1/L99l5FbpIGZVIJXBrTFnCc76F12o+opKNbgwMXb8HW3g5OKlyapaWEoqgMMRWRMgiAgK7/4YWC6Vxaa8pGRXQiluRSWcjNY6AaAy2BhXjqOyUIug4W5TPdz2aBwC1270p+V5jJ8ffpvrIr/AzmFJZBKgEn+bRAe1BE2SnOjH1NBsQazt5zFgYvpkEkliBzbFeN9XWu0r9SsfCz+9nfsv3AbANCmhSXeGdMV/drbG7PkJuH3W1kIjzuHy7ezYa0ww8KRXviXT+smPdaNmhaGojrAUEQN1W11Ad7+7gK++zUVANDSWoEFI7wwspuz0X4xZuUXY9rnp3Dq+j0ozKT4aEIvDDHCnWQ//JaGJbt/R5q6AAAwtlcrLHjaC3ZW8lrvu7Er0Wjx8ZGriDrwB4o1AmRSCTTa0n/an/RsicixXTmgnZoEhqI6wFBEDd2RP+5g0be/4XpmHgDgifb2WDaqC9o6NKvVftPVBZj02UlcSsuGtdIMn0zyhV/bFsYoGQCQXVCM9/ddxuYTNyAIgK2lOeY/7YVxvVqxt6MC1zNyEb4tCWeT7wMAhnZxxNujvbHz7E2s2v8HijRaqCzMsfSZLhjVw4XfIzVqDEV1gKGIGoOCYg02HP4L6w/9haISrW6W8JmD2tdozM71jFyEfvYLUu7mw8Fagc9f7AMvl7r57yMx+R4idp7HpbRsAEBAuxZ4Z0xXeNhb1cnnNUSCIOCrX5LxzvcXkV+sgbXCDEue6YKx/wiQf9zOxr+3ncP5m1kASgPT8tFd4WCtELN0ojrDUFQHGIqoMbmekYtFu3/HkT/uAADcW1hi6TNdMLBTyyrv47ebWZiy6RQycgrh3sISX7zkB7cWlnVVMoDSuwA/SbiGD3/8AwXFWsjNpHi+tyte7OeBNk08HKWrC/Dmjl9x6HLp36l/2xb4f//qhta2hn8nxRotNhz6C2sOXkGxRoCdlRxvj/LG092c67tsojrHUFQHGIqosREEAXvOp2HZd7/jtrp0+oDhXZ2waESXx96hdOJqJl7+/DSyC0vg5WyDmJd6o6V1/Y1PSc7Mw/xvzuse/SKRAE91dsS0JzzQx8OuyV0O+u7XW1jwzW+4n1cMuZkUbw3zxIsBbR47DcOFW2qEb0vS9b6N6OaMZaO8OWaLGhWGojrAUESNVXZBMVbHX0HMsWvQCoCVXIY3hnTElIA25U62uO/3NMyJTURRiRZ+HqWP7aiLu9keRxAEHPsrE58evYaDl9J1671b2WDaE23xdDdnmIs0cWV9ycorxqLdv+kel+Ldygarx/dAB8eqz+1UVKLFRwevYN2hv6DRCrBvJse7Y7oiqItTXZVNVK8YiuoAQxE1dr/fysKCb35D4oPBuZ2dbbB8tDd83G11beJOJSNi53loBSDIyxFrnu9pEvMH/Zmeg00/X8OOs3/rHuviZKPEpAB3TOjjhuaWja/nI+HKHfxn+69IUxdAJpVg1sB2mP1kB8jNahYEf/37Pv697RyupOcAAMb2bIXFI7tAZVn/gZfImBiK6gBDETUFWq2AuNMpWLH3ErLyiwEAz/V2xVvDPBF7Khnv/XAZABDi64p3xniL9giRitzNLcKWX27g8+M3cOfBjOIW5jL8y7c1Xuzn0SgGZecXabBi70V8fvwGAMDD3gqrxndHTzfbx2z5eAXFGkQduIKNR/6CVgAcbRRYMa4bBlVjrBmRqWEoqgMMRdSUZOYUYsXeS9j+YGZqS7kMeUWljw55dWA7vDm0k0mP2yks0eC7c6n45Og1XExVAygddzTY0xHTAj3g10DHHSWl3Ed4XBKuZuQCACb5u2NesCcs5WZG/ZwzN+7hP9vP6T4nxNcV80d0FuUyKVFt1fb3t+j/67d+/Xp4eHhAqVTCx8cHCQkJlbY/fPgwfHx8oFQq0bZtW2zYsMGgzY4dO+Dl5QWFQgEvLy/s2rWrrsonavBaNFPg//2rO7bP8EcnR2tdIFrwdGe8NezxzzETm8JMhnE+rbHntSewZZofnvRsCUEADly8jec2nsDIj45iV+LfKCqp2YN+61uxRotV8X9gXPQxXM3IhaONAptf6oNlo7yNHogAwMfdFt+/FoiX+nlAIgHiTqdg2OojOPpgYDtRUyJqT1FcXBxCQ0Oxfv169OvXDx9//DE++eQTXLhwAW5ubgbtr127Bm9vb7z88st45ZVX8PPPP2PmzJmIjY3FuHHjAADHjx9HYGAg3n77bYwZMwa7du3CokWLcPToUfj5+VWpLvYUUVNVrNFiV+JNONooMaCjg9jl1Fh5444cbRSYHNDGpMcd/ZmejTfiHs4r9Ex3F7w9yrvexvr8cjUT//n6VyTfLZ308wU/N/x3eGdYKYwfxojqQoO+fObn54devXohOjpat65z584YPXo0IiMjDdq/9dZb2L17Ny5evKhbN2PGDJw7dw7Hjx8HAISEhECtVmPv3r26NsOGDYOtrS1iY2OrVBdDEVHjUNG4o2HeTlBZmEMiAaQSCaQP/pQ8+Fkmffhz2fsSiQQyqWHbsn60f/5DWvavqv46w39q/7nqbl4RPjt6DYUlpTNQLx/tjZHdXYz6fVRFbmEJVuy9hC9OlI5jclYp0b5lM8ikEphJpTCTSmAmkzz485+vS3+WySQwl0oftH+0jcTge5Q+eC158L1LJY977+HfR1knZtnfwcNOTYne64fvS8ptL8HD3tDyOkb/ua68thW9X9E+DN6raL3BGxXX+WjTR3t466q/93HfTWXbyM2kRp/eo7a/v0WL/0VFRThz5gzmzZuntz4oKAjHjh0rd5vjx48jKChIb93QoUPx6aefori4GObm5jh+/DjeeOMNgzZRUVEV1lJYWIjCwkLda7VaXc2jISJTZGclx+wnO+Dl/m31xh3tSrwpdmkV6t/RAf/v2W6iPavMSmGGt0d7Y5i3E978+lfcvJ+P1KwCUWqhxq2XW3PsnNlP7DL0iBaKMjIyoNFo4Oio/yBJR0dHpKWllbtNWlpaue1LSkqQkZEBZ2fnCttUtE8AiIyMxNKlS2t4JERk6srGHY3t1QrHr2bil6t3oRWEB0vpnXi6nwUBwoM/H/9+6Z+P9kQA+v9n/miPRUVt/du1wLMm8lT7fu3tse+N/jh6JQP5xSUo0Qgo0ZYuGo1W93NJ2c+aR15rtdBoBRRrhAd/lr5+9DvVCKW9aLr3tHiw/pF22tLvXSMI0GoFXS9cWQ/cw9cP/nywRvf6kY66R7d7tM2j21fcVihnXcWqemnmnz2LFdZYQZtHV9TV5aBHez8f/RyD7/yRFjWdUqIuiX6h+NH/+AVBqPQfhPLaP7q+uvuMiIhAeHi47rVarYarq+vjiyeiBkUikSCgnT0C2tmLXUqD0ExhhmHenNiRmg7RQpG9vT1kMplBD056erpBT08ZJyenctubmZmhRYsWlbapaJ8AoFAooFDwAYlERERNmWh9V3K5HD4+PoiPj9dbHx8fj4CAgHK38ff3N2i/f/9++Pr6wtzcvNI2Fe2TiIiICBD58ll4eDhCQ0Ph6+sLf39/bNy4EcnJyZgxYwaA0staN2/exObNmwGU3mn20UcfITw8HC+//DKOHz+OTz/9VO+ustdffx39+/fHypUrMWrUKHz77bc4cOAAjh49KsoxEhERUcMgaigKCQlBZmYmli1bhtTUVHh7e2PPnj1wd3cHAKSmpiI5OVnX3sPDA3v27MEbb7yBdevWwcXFBWvWrNHNUQQAAQEB2Lp1KxYsWICFCxeiXbt2iIuLq/IcRURERNQ08TEf5eA8RURERA1Pg3/MBxEREZEpYCgiIiIiAkMREREREQCGIiIiIiIADEVEREREABiKiIiIiAAwFBEREREBYCgiIiIiAsBQRERERARA5Md8mKqySb7VarXIlRAREVFVlf3erunDOhiKypGdnQ0AcHV1FbkSIiIiqq7s7GyoVKpqb8dnn5VDq9Xi1q1bsLa2hkQiMeq+1Wo1XF1dkZKSwueq1SN+7+Lg9y4Ofu/i4Pcujn9+79bW1sjOzoaLiwuk0uqPEGJPUTmkUilat25dp59hY2PD/2hEwO9dHPzexcHvXRz83sVR9r3XpIeoDAdaExEREYGhiIiIiAgAQ1G9UygUWLx4MRQKhdilNCn83sXB710c/N7Fwe9dHMb83jnQmoiIiAjsKSIiIiICwFBEREREBIChiIiIiAgAQxERERERAIaierV+/Xp4eHhAqVTCx8cHCQkJYpfUqC1ZsgQSiURvcXJyErusRufIkSMYOXIkXFxcIJFI8M033+i9LwgClixZAhcXF1hYWGDgwIH4/fffxSm2EXnc9z5lyhSD879v377iFNuIREZGonfv3rC2tkbLli0xevRoXL58Wa8Nz3njq8r3boxznqGonsTFxSEsLAzz589HYmIiAgMDERwcjOTkZLFLa9S6dOmC1NRU3XL+/HmxS2p0cnNz0b17d3z00Uflvv/ee+9h1apV+Oijj3Dq1Ck4OTlhyJAhumcMUs087nsHgGHDhumd/3v27KnHChunw4cPY9asWThx4gTi4+NRUlKCoKAg5Obm6trwnDe+qnzvgBHOeYHqRZ8+fYQZM2borfP09BTmzZsnUkWN3+LFi4Xu3buLXUaTAkDYtWuX7rVWqxWcnJyEFStW6NYVFBQIKpVK2LBhgwgVNk6Pfu+CIAiTJ08WRo0aJUo9TUl6eroAQDh8+LAgCDzn68uj37sgGOecZ09RPSgqKsKZM2cQFBSktz4oKAjHjh0Tqaqm4cqVK3BxcYGHhweee+45XL16VeySmpRr164hLS1N79xXKBQYMGAAz/16cOjQIbRs2RIdO3bEyy+/jPT0dLFLanSysrIAAHZ2dgB4zteXR7/3MrU95xmK6kFGRgY0Gg0cHR311js6OiItLU2kqho/Pz8/bN68Gfv27cP//vc/pKWlISAgAJmZmWKX1mSUnd889+tfcHAwvvrqKxw8eBAffPABTp06hSeffBKFhYVil9ZoCIKA8PBwPPHEE/D29gbAc74+lPe9A8Y5583qomAqn0Qi0XstCILBOjKe4OBg3c9du3aFv78/2rVrh88//xzh4eEiVtb08NyvfyEhIbqfvb294evrC3d3d3z//fcYO3asiJU1HrNnz8avv/6Ko0ePGrzHc77uVPS9G+OcZ09RPbC3t4dMJjP4v4T09HSD/5ugumNlZYWuXbviypUrYpfSZJTd7cdzX3zOzs5wd3fn+W8kc+bMwe7du/HTTz+hdevWuvU85+tWRd97eWpyzjMU1QO5XA4fHx/Ex8frrY+Pj0dAQIBIVTU9hYWFuHjxIpydncUupcnw8PCAk5OT3rlfVFSEw4cP89yvZ5mZmUhJSeH5X0uCIGD27NnYuXMnDh48CA8PD733ec7Xjcd97+WpyTnPy2f1JDw8HKGhofD19YW/vz82btyI5ORkzJgxQ+zSGq25c+di5MiRcHNzQ3p6OpYvXw61Wo3JkyeLXVqjkpOTgz///FP3+tq1a0hKSoKdnR3c3NwQFhaGd999Fx06dECHDh3w7rvvwtLSEhMmTBCx6oavsu/dzs4OS5Yswbhx4+Ds7Izr16/jv//9L+zt7TFmzBgRq274Zs2ahS1btuDbb7+FtbW1rkdIpVLBwsICEomE53wdeNz3npOTY5xzvlb3rlG1rFu3TnB3dxfkcrnQq1cvvVsJyfhCQkIEZ2dnwdzcXHBxcRHGjh0r/P7772KX1ej89NNPAgCDZfLkyYIglN6ivHjxYsHJyUlQKBRC//79hfPnz4tbdCNQ2feel5cnBAUFCQ4ODoK5ubng5uYmTJ48WUhOTha77AavvO8cgLBp0yZdG57zxve4791Y57zkwYcRERERNWkcU0REREQEhiIiIiIiAAxFRERERAAYioiIiIgAMBQRERERAWAoIiIiIgLAUEREREQEgKGIiKhCEokE33zzjdhlEFE9YSgiIpM0ZcoUSCQSg2XYsGFil0ZEjRSffUZEJmvYsGHYtGmT3jqFQiFSNUTU2LGniIhMlkKhgJOTk95ia2sLoPTSVnR0NIKDg2FhYQEPDw9s375db/vz58/jySefhIWFBVq0aIHp06cjJydHr81nn32GLl26QKFQwNnZGbNnz9Z7PyMjA2PGjIGlpSU6dOiA3bt36967d+8eXnjhBTg4OMDCwgIdOnQwCHFE1HAwFBFRg7Vw4UKMGzcO586dw8SJE/H888/j4sWLAIC8vDwMGzYMtra2OHXqFLZv344DBw7ohZ7o6GjMmjUL06dPx/nz57F79260b99e7zOWLl2K8ePH49dff8Xw4cPxwgsv4O7du7rPv3DhAvbu3YuLFy8iOjoa9vb29fcFEJFxGf1RtkRERjB58mRBJpMJVlZWesuyZcsEQSh9avaMGTP0tvHz8xNeffVVQRAEYePGjYKtra2Qk5Oje//7778XpFKpkJaWJgiCILi4uAjz58+vsAYAwoIFC3Svc3JyBIlEIuzdu1cQBEEYOXKk8OKLLxrngIlIdBxTREQma9CgQYiOjtZbZ2dnp/vZ399f7z1/f38kJSUBAC5evIju3bvDyspK936/fv2g1Wpx+fJlSCQS3Lp1C4MHD660hm7duul+trKygrW1NdLT0wEAr776KsaNG4ezZ88iKCgIo0ePRkBAQI2OlYjEx1BERCbLysrK4HLW40gkEgCAIAi6n8trY2FhUaX9mZubG2yr1WoBAMHBwbhx4wa+//57HDhwAIMHD8asWbPw/vvvV6tmIjINHFNERA3WiRMnDF57enoCALy8vJCUlITc3Fzd+z///DOkUik6duwIa2trtGnTBj/++GOtanBwcMCUKVPw5ZdfIioqChs3bqzV/ohIPOwpIiKTVVhYiLS0NL11ZmZmusHM27dvh6+vL5544gl89dVXOHnyJD799FMAwAsvvIDFixdj8uTJWLJkCe7cuYM5c+YgNDQUjo6OAIAlS5ZgxowZaNmyJYKDg5GdnY2ff/4Zc+bMqVJ9ixYtgo+PD7p06YLCwkJ899136Ny5sxG/ASKqTwxFRGSyfvjhBzg7O+ut69SpEy5dugSg9M6wrVu3YubMmXBycsJXX30FLy8vAIClpSX27duH119/Hb1794alpSXGjRuHVatW6fY1efJkFBQUYPXq1Zg7dy7s7e3x7LPPVrk+uVyOiIgIXL9+HRYWFggMDMTWrVuNcOREJAaJIAiC2EUQEVWXRCLBrl27MHr0aLFLIaJGgmOKiIiIiMBQRERERASAY4qIqIHilX8iMjb2FBERERGBoYiIiIgIAEMREREREQCGIiIiIiIADEVEREREABiKiIiIiAAwFBEREREBYCgiIiIiAsBQRERERAQA+P82u5oL/+jI+wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the training loss\n",
    "plt.plot(epoch_losses, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2598b529f5b9ffaa",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 62/62 [00:05<00:00, 11.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9488752556237219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Switch to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "# Add tqdm progress bar\n",
    "for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    batch_preds = np.argmax(logits, axis=1)\n",
    "    predictions.extend(batch_preds)\n",
    "    true_labels.extend(label_ids)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4de4e7b",
   "metadata": {},
   "source": [
    "### K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1e96fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Training Epoch 1/25, Fold 1/10:   0%|          | 0/184 [00:46<?, ?it/s, loss=0.384]\n",
      "Validation, Fold 1/10:   0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/25, Fold 1/10:   0%|          | 0/184 [00:46<?, ?it/s, loss=0.188]\n",
      "Validation, Fold 1/10:   0%|          | 0/21 [00:47<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/25, Fold 1/10:   0%|          | 0/184 [00:47<?, ?it/s, loss=0.0818]\n",
      "Validation, Fold 1/10:   0%|          | 0/21 [00:48<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\GithubRepo\\Amazon_QA_Robot\\training_bert.ipynb Cell 15\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GithubRepo/Amazon_QA_Robot/training_bert.ipynb#X22sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(b_input_ids, attention_mask\u001b[39m=\u001b[39mb_input_mask, labels\u001b[39m=\u001b[39mb_labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GithubRepo/Amazon_QA_Robot/training_bert.ipynb#X22sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m loss \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mloss\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/GithubRepo/Amazon_QA_Robot/training_bert.ipynb#X22sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GithubRepo/Amazon_QA_Robot/training_bert.ipynb#X22sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GithubRepo/Amazon_QA_Robot/training_bert.ipynb#X22sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the KFold cross-validator\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize performance metric list\n",
    "fold_performance = []\n",
    "\n",
    "# Parameters\n",
    "batch_size = 8\n",
    "epochs = 25\n",
    "learning_rate = 2e-5\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Start the KFold cross-validation\n",
    "for fold, (train_ids, test_ids) in enumerate(kf.split(dataset)):\n",
    "    print(f\"FOLD {fold}\")\n",
    "    print(\"-------------------------------\")\n",
    "\n",
    "    # Split the data into training and validation sets for the current fold\n",
    "    train_subset = Subset(dataset, train_ids)\n",
    "    test_subset = Subset(dataset, test_ids)\n",
    "    \n",
    "    train_dataloader = DataLoader(train_subset, sampler=RandomSampler(train_subset), batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_subset, sampler=SequentialSampler(test_subset), batch_size=batch_size)\n",
    "    \n",
    "    # Initialize the BERT model for sequence classification\n",
    "    model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "    model.to(device)\n",
    "    \n",
    "    # Define the optimizer\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    # Training loop for the current fold\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        \n",
    "        train_progress_bar = tqdm(train_dataloader, desc=f\"Training Epoch {epoch+1}/{epochs}, Fold {fold+1}/10\")\n",
    "        \n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "            \n",
    "            model.zero_grad()\n",
    "            \n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_progress_bar.set_postfix(loss=total_loss/(step+1))\n",
    "        \n",
    "        train_progress_bar.close()\n",
    "        \n",
    "        # Calculate the average loss over the training data.\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        \n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        total_eval_accuracy = 0\n",
    "        total_eval_loss = 0\n",
    "        \n",
    "        eval_progress_bar = tqdm(test_dataloader, desc=f\"Validation, Fold {fold+1}/10\")\n",
    "        \n",
    "        for batch in eval_progress_bar:\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            total_eval_loss += loss.item()\n",
    "            \n",
    "            # Move logits and labels to CPU\n",
    "            logits = outputs.logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Report the final accuracy for this validation run.\n",
    "        avg_val_accuracy = total_eval_accuracy / len(test_dataloader)\n",
    "        print(f\"Validation accuracy: {avg_val_accuracy}\")\n",
    "        \n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_val_loss = total_eval_loss / len(test_dataloader)\n",
    "        \n",
    "        # Record all statistics from this epoch.\n",
    "        fold_performance.append({\n",
    "            'fold': fold,\n",
    "            'epoch': epoch,\n",
    "            'train_loss': avg_train_loss,\n",
    "            'val_loss': avg_val_loss,\n",
    "            'val_accuracy': avg_val_accuracy\n",
    "        })\n",
    "\n",
    "# Calculate and print the average performance across all folds\n",
    "average_performance = {\n",
    "    'avg_train_loss': np.mean([x['train_loss'] for x in fold_performance]),\n",
    "    'avg_val_loss': np.mean([x['val_loss'] for x in fold_performance]),\n",
    "    'avg_val_accuracy': np.mean([x['val_accuracy'] for x in fold_performance])\n",
    "}\n",
    "print(f\"Average performance across all folds: {average_performance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andy Cui\\.conda\\envs\\nlp\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1:   3%|▎         | 2/72 [00:47<27:40, 23.72s/it, loss=0.0166] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\GithubRepo\\Amazon_QA_Robot\\training_bert.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GithubRepo/Amazon_QA_Robot/training_bert.ipynb#X16sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(b_input_ids, token_type_ids\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, attention_mask\u001b[39m=\u001b[39mb_input_mask, labels\u001b[39m=\u001b[39mb_labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GithubRepo/Amazon_QA_Robot/training_bert.ipynb#X16sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m loss \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mloss\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/GithubRepo/Amazon_QA_Robot/training_bert.ipynb#X16sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GithubRepo/Amazon_QA_Robot/training_bert.ipynb#X16sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GithubRepo/Amazon_QA_Robot/training_bert.ipynb#X16sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "batch_size = 16\n",
    "epochs = 30\n",
    "\n",
    "# Prepare for epoch_losses\n",
    "epoch_losses = []\n",
    "\n",
    "# Create dataloader\n",
    "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "model.train()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\")\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        # b_input_ids, b_input_mask, b_labels = batch\n",
    "        b_input_ids, b_input_mask, b_labels = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
    "        model.zero_grad()\n",
    "\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the progress bar\n",
    "        progress_bar.set_postfix({'loss': total_loss/len(train_dataloader)})\n",
    "        \n",
    "    # Calculate and store the average loss for this epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    epoch_losses.append(avg_loss)\n",
    "    \n",
    "    # Save the model after each epoch\n",
    "    # model_save_file = os.path.join(model_save_path, f'bert_model_epoch_{epoch+1}.pt')\n",
    "    # torch.save(model.state_dict(), model_save_file)\n",
    "\n",
    "    # Closing the progress bar and printing the epoch loss\n",
    "    progress_bar.close()\n",
    "    print(f\"Epoch {epoch+1} finished. Loss: {total_loss/len(train_dataloader)}\")\n",
    "\n",
    "# Save\n",
    "model_save_path = 'models'  \n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "final_model_save_file = os.path.join(model_save_path, 'bert_final_model_2.pt')\n",
    "torch.save(model.state_dict(), final_model_save_file)\n",
    "\n",
    "# print paramter\n",
    "print(\"Training Parameters:\")\n",
    "print(f\"Batch Size: {batch_size}\")\n",
    "print(f\"Epochs: {epochs}\")\n",
    "print(f\"Learning Rate: {optimizer.defaults['lr']}\")\n",
    "print(f\"Beta1: {optimizer.defaults['betas'][0]}\")\n",
    "print(f\"Beta2: {optimizer.defaults['betas'][1]}\")\n",
    "print(f\"Training completed. Final model saved to {final_model_save_file}\")\n",
    "\n",
    "# Plotting the training loss\n",
    "plt.plot(epoch_losses, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
